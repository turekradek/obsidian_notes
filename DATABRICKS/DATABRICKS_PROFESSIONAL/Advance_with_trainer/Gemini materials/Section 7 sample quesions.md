# **Sample Questions**
Question 1 Objective: Identify the results of running a command on a Delta Lake table created with a query A Delta Lake table was created with the query: CREATE TABLE dev.my_table USING DELTA LOCATION "/mnt/dev/my_table" Realizing that the table needs to be used by other and its name is misleading, the below code was executed: ALTER TABLE dev.my_table RENAME TO dev.our_table Which result will occur after running the second command? A. The table name change is recorded in the Delta transaction log. B. The table reference in the metastore is updated and all data files are moved. C. The table reference in the metastore is updated and no data is changed. D. A new Delta transaction log is created for the renamed table. E. All related files and metadata are dropped and recreated in a single ACID transaction.

Question 2 Objective: Deduplicate data against previously processed records as it is inserted into Delta table. A data engineer is developing an ETL workflow that could see late-arriving, duplicate records from its single source. The data engineer knows that they can deduplicate the records within the batch, but they are looking for another solution. Which approach allows the data engineer to deduplicate data against previously processed records as it is inserted into a Delta table? A. VACUUM the Delta table after each batch completes. B. Rely on Delta Lake schema enforcement to prevent duplicate records. C. Set the configuration delta.deduplicate = true. D. Perform a full outer join on a unique key and overwrite existing data. E. Perform an insert-only merge with a matching condition on a unique key

Question 3 Objective: Identify how to configure all tables in the Lakehouse as external, unmanaged Delta Lake tables The data architect has mandated that all tables in the Lakehouse should be configured as external, unmanaged Delta Lake tables. Which approach will ensure that this requirement is met? A. Whenever a table is being created, make sure that the LOCATION keyword is used. B. When tables are created, make sure that the EXTERNAL keyword is used in the CREATE TABLE statement. C. When the workspace is being configured, make sure that external cloud object storage has been mounted. D. Whenever a database is being created, make sure that the LOCATION keyword is used. E. Whenever a table is being created, make sure that the LOCATION and UNMANAGED keywords are used.

Question 4 Objective: Describe permission controls for Databricks jobs A data engineering team is trying to transfer ownership from its Databricks Workflows away from an individual that has switched teams. However, they are unsure how permission controls specifically for Databricks Jobs work. Which statement correctly describes permission controls for Databricks Jobs? A. The creator of a Databricks Job will always have "Owner" privileges; this configuration cannot be changed. B. Databricks Jobs must have exactly one owner; "Owner" privileges cannot be assigned to a group. C. Other than the default "admins" group, only individual users can be granted privileges on Jobs. D. Only workspace administrators can grant "Owner" privileges to a group. E. A user can only transfer Job ownership to a group if they are also a member of that group

Question 5 Objective: Identify methods for installing python packagesâ€¦ A data engineer needs to use a Python package to process data. As a result, they need to install the Python package on all of the nodes in the currently active cluster. What describes a method of installing a Python package scoped at the notebook level to all nodes in the currently active cluster? A. Use %pip install in a notebook cell B. Use %sh pip install in a notebook cell C. Run source env/bin/activate in a notebook setup script D. Install libraries from PyPI using the cluster UI E. Use b in a notebook cell