# **Optional Lab - A Data Factory solution for moving and transforming data with dataflows and data pipelines (Optional)**

**Introduction**

This lab helps you accelerate the evaluation process for Data Factory in Microsoft Fabric by providing a step-by-step guidance for a full data integration scenario within one hour. By the end of this tutorial, you understand the value and key capabilities of Data Factory and know how to complete a common end-to-end data integration scenario.

**Objective**

The lab is divided into three modules:

- Exercise 1: Create a pipeline with Data Factory to ingest raw data from a Blob storage to a Bronze table in a data Lakehouse.
    
- Exercise 2: Transform data with a dataflow in Data Factory to process the raw data from your Bronze table and move it to a Gold table in the data Lakehouse.
    
- Exercise 3: Automate and send notifications with Data Factory to send an email to notify you once all the jobs are complete, and finally, setup the entire flow to run on a scheduled basis.
    

# **Exercise 1: Create a pipeline with Data Factory**

> **Important**: Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease product that may be substantially modified before it's released. Microsoft makes no warranties, expressed or implied, with respect to the information provided here. Refer toÂ **`https://learn.microsoft.com/en-us/azure/data-factory/`**Â for the service in Azure.

## **Task 1: Create a workspace**

Before working with data in Fabric, create a workspace with the Fabric trial enabled.

1. Open your browser, navigate to the address bar, and type or paste the following URL:Â **`https://app.fabric.microsoft.com/`**Â then press theÂ **Enter**Â button.
    
    ![jssotlnr.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/jssotlnr.jpg)
    
    > **Note**: If you are directed to Microsoft Fabric Home page, then skip steps from #2 to #4.
    
2. In theÂ **Microsoft Fabric**Â window, enter your credentials, and click on theÂ **Submit**Â button.
    
    ![oxvk8yku.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/oxvk8yku.jpg)
    
3. Then, in theÂ **Microsoft**Â window, enter the password and click on theÂ **Sign in**Â button**.**
    
    ![1kyp2nb0.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/1kyp2nb0.jpg)
    
4. InÂ **Stay signed in?**Â window, click on theÂ **Yes**Â button.
    
    ![0vs5wz9t.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/0vs5wz9t.jpg)
    
5. In theÂ **Microsoft Fabric**Â home page, select theÂ **Power BI**Â template.
    
    ![vuc7w3jv.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/vuc7w3jv.jpg)
    
6. In theÂ **Power BI Home**Â page left-sided navigation bar, selectÂ **Workspaces**Â (the icon looks similar to ðŸ—‡).
    
    ![p6o4gh9e.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/p6o4gh9e.jpg)
    
7. In the Workspaces pane, selectÂ **+**Â **New workspace**.
    
    ![o19d0tgy.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/o19d0tgy.jpg)
    
8. In theÂ **Create a workspace**Â tab, enter the following details and click on theÂ **Apply**Â button.
    
    |||
    |---|---|
    |**Name**|**`Data-FactoryXX`**(XX can be a unique number) (here, we enteredÂ **Dataflow_Fabric29)**|
    |**Advanced**|UnderÂ **License mode**, selectÂ **Trial**|
    |**Default storage format**|**`SmallÂ dataset storage format`**|
    
    ![do6mmdau.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/do6mmdau.jpg)
    
    ![ftckft5n.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/ftckft5n.jpg)
    
    ![5dzqs4qh.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/5dzqs4qh.jpg)
    
9. Wait for the deployment to complete. It'll take approximately 2-3 minutes.
    

## **Task 2: Create a data pipeline**

1. Select the default Power BI icon at the bottom left of the screen, and switch to theÂ **Data Factory**Â experience.
    
    ![lj5kqy3i.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/lj5kqy3i.jpg)
    
2. In theÂ **Data Factory**Â Home page, click onÂ **Data pipeline (Preview)**Â as shown in the below image.
    
    ![nbn3w711.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/nbn3w711.jpg)
    
3. In theÂ **New pipeline**Â dialog box, enterÂ **`First_Pipeline1`**Â in theÂ **Name**Â field, then click on theÂ **Create**Â button.
    
    ![xzzqce80.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/xzzqce80.jpg)
    

## **Task 3: Use a Copy activity in the pipeline to load sample data to a data Lakehouse**

1. In theÂ **First_Pipeline1**Â home page SelectÂ **Copy data**Â to open the copy assistant tool.
    
    ![exlnke1e.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/exlnke1e.jpg)
    
2. TheÂ **Copy data**Â dialog is displayed with the first step,Â **Choose data source**, highlighted. Scroll down if necessary to theÂ **Data sources**Â section, and select theÂ **Azure Blob Storage**Â data source type. Then selectÂ **Next**.
    
    ![6p8pksts.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/6p8pksts.jpg)
    
3. In the next step, selectÂ **Create new connection**Â and then provide the URL for the blob storage hosting the sample data provided for this tutorial, atÂ **`https://nyctaxisample.blob.core.windows.net/sample`**. The authentication kind isÂ **Anonymous**. SelectÂ **Next**Â after providing the URL.
    
    ![9gnbze03.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/9gnbze03.jpg)
    
4. TheÂ **Connect to data source**Â step appears, and initially, you see an errorÂ **Unable to list files**, because permissions have only been granted to theÂ **sample**Â folder in the blob storage. Provide the folder nameÂ **`sample`**, and selectÂ **Retry**.
    
    ![sebg65y5.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/sebg65y5.jpg)
    
    > **Note:**Â The blob storage folder is case sensitive and should be in all lower case.*
    
5. The blob storage browser appears next. Select theÂ **NYC-Taxi-Green-2015-01.parquet**Â file, and wait for the data preview to appear. Then selectÂ **Next**.
    
    ![7308xstg.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/7308xstg.jpg)
    
6. For theÂ **Choose data destination**Â step of the copy assistant, selectÂ **Lakehouse**Â and thenÂ **Next**.
    
    ![h7xzmqzc.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/h7xzmqzc.jpg)
    
7. SelectÂ **Create new Lakehouse**Â on the data destination configuration page that appears, and enter a name for the new LakehouseÂ **`Tutorial_Lakehouse`**. Then selectÂ **Next**Â again.
    
    ![8675zw39.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/8675zw39.jpg)
    
8. Now configure the details of your Lakehouse destination on theÂ **Select and map to folder path or table.**Â page. SelectÂ **Tables**Â for theÂ **Root folder**, provide a table nameÂ **Bronze**, and select theÂ **Next**.
    
    ![wgjdpv8b.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/wgjdpv8b.jpg)
    
9. Finally, on theÂ **Review + save**Â page of the copy data assistant, review the configuration. For this lab, uncheck theÂ **Start data transfer immediately**Â checkbox, since we run the activity manually in the next step. Then selectÂ **OK**.
    
    ![8xgml7en.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/8xgml7en.jpg)
    

## **Task 4: Run and view the results of your Copy activity**.

1. On theÂ **Home**Â tab of the pipeline editor window, then select theÂ **Run**Â button.
    
    ![hefls25w.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/hefls25w.jpg)
    
2. In theÂ **Save and run?**Â dialog box, click onÂ **Save and run**Â button to execute these activities.
    
    ![9kftqud3.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/9kftqud3.jpg)
    
    ![uup1agi2.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/uup1agi2.jpg)
    
    ![wwbn0u0q.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/wwbn0u0q.jpg)
    
3. You can monitor the run and check the results on theÂ **Output**Â tab below the pipeline canvas. Select theÂ **activity name**Â asÂ **Copy_ihy**Â to view the run details.
    
    ![vs5xdhwm.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/vs5xdhwm.jpg)
    
4. The run details show 1,508,501 rows read and written.
    
    ![fjla1gjq.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/fjla1gjq.jpg)
    
5. Expand theÂ **Duration breakdown**Â section to see the duration of each stage of the Copy activity. After reviewing the copy details, selectÂ **Close**.
    
    ![17yblvd2.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/17yblvd2.jpg)
    

## **Exercise 2: Transform data with a dataflow in Data Factory**

## **Task 1: Get data from a Lakehouse table**

1. On theÂ **First_Pipeline 1**Â page, from the sidebar selectÂ **Create.**
    
    ![vocp1sq3.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/vocp1sq3.jpg)
    
2. On theÂ **Data Factory Data-FactoryXX**Â home page, to create a new dataflow gen2 click onÂ **Dataflow Gen2 (Preview)**Â under theÂ **Data Factory.**
    
    ![dn1270gp.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/dn1270gp.jpg)
    
3. From the new dataflow menu, under theÂ **Power Query**Â pane click onÂ **Get data**, then selectÂ **More...**.
    
    ![qmnk7vjk.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/qmnk7vjk.jpg)
    
4. In theÂ **Choose data source**Â tab, search box search typeÂ **`Lakehouse`**Â and then click on theÂ **Lakehouse**Â connector.
    
    ![17i4mqpf.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/17i4mqpf.jpg)
    
5. TheÂ **Connect to data source**Â dialog appears, selectÂ **Edit connection.**
    
    ![m8wakwk0.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/m8wakwk0.jpg)
    
6. In theÂ **Connect to data source**Â dialog box, selectÂ **sign in**Â using your Power BI organizational account to set the identity that the dataflow uses to access the lakehouse.
    
    ![ztw36ue8.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/ztw36ue8.jpg)
    
    ![7pxrsgir.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/7pxrsgir.jpg)
    
7. InÂ **Connect to data source**Â dialog box, selectÂ **Next.**
    
    ![5fl45fvs.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/5fl45fvs.jpg)
    
8. TheÂ **Choose data**Â dialog is displayed. Use the navigation pane to find the Lakehouse you created for the destination in the prior module, and select theÂ **Tutorial_Lakehouse**Â data table then click onÂ **Create**Â button.
    
    ![9k1se9ap.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/9k1se9ap.jpg)
    
9. Once your canvas is populated with the data, you can setÂ **column profile**Â information, as this is useful for data profiling. You can apply the right transformation and target the right data values based on it.
    
10. To do this, selectÂ **Options**Â from the ribbon pane, then select the first three options underÂ **Column profile**, and then selectÂ **OK**.
    
    ![03lpegeq.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/03lpegeq.jpg)
    
    ![no9vm1d8.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/no9vm1d8.jpg)
    

## **Task 2: Transform the data imported from the Lakehouse**

1. Select the data type icon in the column header of the second column,Â **IpepPickupDatetime**, to display a dropdown menu and select theÂ **Change type**Â from the menu to convert the column from theÂ **Date/Time**Â toÂ **Date**Â type.
    
    ![4p7xua5e.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/4p7xua5e.jpg)
    
2. On theÂ **Home**Â tab of the ribbon, select theÂ **Choose columns**Â option from theÂ **Manage columns**Â group.
    
    ![vxrenrxg.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/vxrenrxg.jpg)
    
3. On theÂ **Choose columns**Â dialog,Â **deselect**Â some columns listed here, then selectÂ **OK**.
    
    - lpepDropoffDatetime
    - puLocationId
    - doLocationId
    - pickupLatitude
    - dropoffLongitude
    - rateCodeID
    
    ![7msgj73u.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/7msgj73u.jpg)
    
4. Select theÂ **storeAndFwdFlag**Â column's filter and sort dropdown menu. (If you see a warningÂ **List may be incomplete**, selectÂ **Load more**Â to see all the data.)
    
    ![rszohe4m.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/rszohe4m.jpg)
    
5. SelectÂ **'Y'**Â to show only rows where a discount was applied, and then selectÂ **OK**.
    
    ![rfixjmbp.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/rfixjmbp.jpg)
    
6. Select theÂ **Ipep_Pickup_Datetime**Â column sort and filter dropdown menu, then selectÂ **Date filters**, and choose theÂ **Between...**Â filter provided for Date and Date/Time types.
    
    ![bvczapk5.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/bvczapk5.jpg)
    
7. In theÂ **Filter rows**Â dialog, select dates betweenÂ **January 1, 2015**, andÂ **January 31, 2015**, then selectÂ **OK**.
    
    ![cmig1hew.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/cmig1hew.jpg)
    

### **Task 3: Connect to a CSV file containing discount data**

Now, with the data from the trips in place, we want to load the data that contains the respective discounts for each day and VendorID, and prepare the data before combining it with the trips data.

1. From theÂ **Home**Â tab in the dataflow editor menu, select theÂ **Get data**Â option, and then chooseÂ **Text/CSV**.
    
    ![la673ie3.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/la673ie3.jpg)
    
2. In theÂ **Connect to data source**Â pane, underÂ **Connection settings**, selectÂ **Upload file (Preview)**Â radio button, then click onÂ **Browse**Â button and browse your VMÂ **C:\LabFiles**, then select theÂ **NYC-Taxi-Green-Discounts**Â file and click on theÂ **Open**Â button.
    
    ![naroavjz.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/naroavjz.jpg)
    
    ![kihybdf5.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/kihybdf5.jpg)
    
3. In theÂ **Connect to data source**Â pane, click on theÂ **Next**Â button.
    
    ![a3bk0hwp.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/a3bk0hwp.jpg)
    
4. On theÂ **Preview file data**Â dialog, selectÂ **Create**.
    
    ![w4ppgwxy.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/w4ppgwxy.jpg)
    

## **Task 4: Transform the discount data**

1. Reviewing the data, we see the headers appear to be in the first row. Promote them to headers by selecting the table's context menu at the top left of the preview grid area to selectÂ **Use first row as headers**.
    
    ![y74172x6.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/y74172x6.jpg)
    
    > **Note:**Â After promoting the headers, you can see a new step added to theÂ **Applied steps**Â pane at the top of the dataflow editor to the data types of your columns.*
    
2. Right-click theÂ **VendorID**Â column, and from the context menu displayed, select the optionÂ **Unpivot other columns**. This allows you to transform columns into attribute-value pairs, where columns become rows.
    
    ![lavqnrsp.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/lavqnrsp.jpg)
    
3. With the table unpivoted, rename theÂ **Attribute**Â andÂ **Value**Â columns by double-clicking them and changingÂ **Attribute**Â toÂ **Date**Â andÂ **Value**Â toÂ **Discount**.
    
    ![0wa0lftz.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/0wa0lftz.jpg)
    
    ![h9jxl3nj.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/h9jxl3nj.jpg)
    
    ![8ctmzett.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/8ctmzett.jpg)
    
    ![g8of289d.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/g8of289d.jpg)
    
4. Change the data type of the Date column by selecting the data type menu to the left of the column name and choosingÂ **Date**.
    
    ![h7ywmaj6.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/h7ywmaj6.jpg)
    
5. Select theÂ **Discount**Â column and then select theÂ **Transform**Â tab on the menu. SelectÂ **Number column**, and then selectÂ **Standard**Â numeric transformations from the submenu, and chooseÂ **Divide**.
    
    ![7verumhy.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/7verumhy.jpg)
    
6. On theÂ **Divide**Â dialog, enter the valueÂ **`100`**, then click onÂ **OK**Â button.
    
    ![0v5i4atp.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/0v5i4atp.jpg)
    

### **Task 5: Combine trips and discounts data**

The next step is to combine both tables into a single table that has the discount that should be applied to the trip, and the adjusted total.

1. First, toggle theÂ **Diagram view**Â button so you can see both of your queries.
    
    ![bvlb7bpx.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/bvlb7bpx.jpg)
    
2. Select theÂ **Nyc_Taxi_Green_2..**Â query, and on theÂ **Home**Â tab, Select theÂ **Combine**Â menu and chooseÂ **Merge queries**, thenÂ **Merge queries as new**.
    
    ![e4x09jp8.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/e4x09jp8.jpg)
    
3. On theÂ **Merge**Â dialog, selectÂ **Generated-NYC-Taxi-Green-Discounts**Â from theÂ **Right table for merge**Â drop down, and then select the "**light bulb**" icon on the top right of the dialog to see the suggested mapping of columns between the three tables.
    
    ![1z0m8bz8.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/1z0m8bz8.jpg)
    
4. Choose each of the two suggested column mappings, one at a time, mapping the VendorID and date columns from both tables. When both mappings are added, the matched column headers are highlighted in each table.
    
    ![u7nvtqp6.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/u7nvtqp6.jpg)
    
5. A message is shown asking you to allow combining data from multiple data sources to view the results. SelectÂ **OK**
    
    ![g61v28oq.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/g61v28oq.jpg)
    
6. Notice how a new query was created in Diagram view showing the relationship of the new Merge query with the two queries you previously created. Looking at the table pane of the editor, scroll to the right of the Merge query column list to see a new column with table values is present. This is the "Generated NYC Taxi-Green-Discounts" column, and its type isÂ **[Table]**. In the column header there's an icon with two arrows going in opposite directions, allowing you to select columns from the table. Deselect all of the columns exceptÂ **Discount**, and then selectÂ **OK**.
    
    ![6tz511wu.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/6tz511wu.jpg)
    
    ![c37ylwyh.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/c37ylwyh.jpg)
    
7. With the discount value now at the row level, we can create a new column to calculate the total amount after discount. To do so, select theÂ **Add column**Â tab at the top of the editor, and chooseÂ **Custom column**Â from theÂ **General**Â group.
    
    ![vwmc63hz.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/vwmc63hz.jpg)
    
8. On theÂ **Custom column**Â dialog, you can use theÂ [Power Query formula language (also known as M)](https://learn.microsoft.com/en-us/powerquery-m)Â to define how your new column should be calculated. EnterÂ **TotalAfterDiscount**Â for theÂ **New column name**, selectÂ **Currency**Â for theÂ **Data type**, and provide the following M expression for theÂ **Custom column formula**:
    
    **`ifÂ [totalAmount]Â >Â 0Â thenÂ [totalAmount]Â *Â (Â 1Â -[Discount]Â )Â elseÂ [totalAmount]`**
    
    Then selectÂ **OK**.
    
    ![04ntcz0l.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/04ntcz0l.jpg)
    
    ![4rlezej5.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/4rlezej5.jpg)
    
9. Select the newly createÂ **TotalAfterDiscount**Â column and then select theÂ **Transform**Â tab at the top of the editor window. On theÂ **Number column**Â group, select theÂ **Rounding**Â drop down and then chooseÂ **Round...**.
    
    ![hy2ijd76.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/hy2ijd76.jpg)
    
10. On theÂ **Round**Â dialog, enterÂ **`2`**Â for the number of decimal places and then selectÂ **OK**.
    
    ![v5wzpr1h.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/v5wzpr1h.jpg)
    
11. Change the data type of theÂ **IpepPickupDatetime**Â fromÂ **Date**Â toÂ **Date/Time**.
    
    ![u828x0nc.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/u828x0nc.jpg)
    
    ![cphc2jx3.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/cphc2jx3.jpg)
    
12. Finally, expand theÂ **Query settings**Â pane from the right side of the editor if it isn't already expanded, and rename the query fromÂ **Merge**Â toÂ **Output**.
    
    ![51tludj2.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/51tludj2.jpg)
    
    ![sm5uz4xd.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/sm5uz4xd.jpg)
    

### **Task 6: Load the output query to a table in the Lakehouse**

With the output query now fully prepared and with data ready to output, we can define the output destination for the query.

1. Select theÂ **Output**Â merge query created previously. Then select theÂ **Home**Â tab in the editor, andÂ **Add data destination**Â from theÂ **Query**Â grouping, to select aÂ **Lakehouse**Â destination.
    
    ![i8cfdqnw.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/i8cfdqnw.jpg)
    
2. On theÂ **Connect to data destination**Â dialog, your connection should already be selected. SelectÂ **Next**Â to continue.
    
    ![56tk5p7a.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/56tk5p7a.jpg)
    
3. On theÂ **Choose destination target**Â dialog, browse to the Lakehouse where you wish to load the data and name the new tableÂ **`nyc_taxi_with_discounts`**, then selectÂ **Next**Â again.
    
    ![r8hiwiwz.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/r8hiwiwz.jpg)
    
4. On theÂ **Choose destination settings**Â dialog, leave the defaultÂ **Replace**Â update method, double check that your columns are mapped correctly, and selectÂ **Save settings**.
    
    ![ymy51lj7.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/ymy51lj7.jpg)
    
5. Back in the main editor window, confirm that you see your output destination on theÂ **Query settings**Â pane for theÂ **Output**Â table, and then selectÂ **Publish**.
    
    ![9ciqo2du.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/9ciqo2du.jpg)
    
    ![93yzjbxr.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/93yzjbxr.jpg)
    
6. On the workspace page, you can rename your dataflow by selecting the ellipsis to the right of the dataflow name that appears after you select the row, and choosingÂ **Properties**.
    
    ![wp0yjed0.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/wp0yjed0.jpg)
    
7. In theÂ **Dataflow 1**Â dialog box, enterÂ **`nyc_taxi_data_with_discounts`**Â in the name box, then selectÂ **Save**.
    
    ![xc6v8sgb.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/xc6v8sgb.jpg)
    
8. Select the refresh icon for the dataflow after selecting its row, and when complete, you should see your new Lakehouse table created as configured in theÂ **Data destination**Â settings.
    
    ![q2su9i1o.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/q2su9i1o.jpg)
    
9. In theÂ **Data_FactoryXX**Â pane, selectÂ **Tutorial_Lakehouse**Â to view the new table loaded there.
    
    ![imfgwbzb.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/imfgwbzb.jpg)
    
    ![rj8v1ia0.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/rj8v1ia0.jpg)
    

# **Exercise 3: Automate and send notifications with Data Factory**

> **Important**Â Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease product that may be substantially modified before it's released. Microsoft makes no warranties, expressed or implied, with respect to the information provided here. Refer toÂ [**Azure Data Factory documentation**](https://learn.microsoft.com/en-us/azure/data-factory/)Â for the service in Azure.

## **Task 1: Add an Office 365 Outlook activity to your pipeline**

1. FromÂ **Tutorial_Lakehouse**Â page, navigate and click onÂ **Data_FactoryXX**Â Workspace on the left-sided navigation menu.
    
    ![jbe0d1ck.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/jbe0d1ck.jpg)
    
2. In theÂ **Data_FactoryXX**Â view, select theÂ **First_Pipeline1**.
    
    ![va42e4ky.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/va42e4ky.jpg)
    
3. Select theÂ **Activities**Â tab in the pipeline editor and find theÂ **Office Outlook**Â activity.
    
    ![4ks8iyxs.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/4ks8iyxs.jpg)
    
4. Select and drag theÂ **On success**Â path (a green checkbox on the top right side of the activity in the pipeline canvas) from yourÂ **Copy activity**Â to your newÂ **Office 365 Outlook**Â activity.
    
    ![isc6qx1l.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/isc6qx1l.jpg)
    
5. Select the Office 365 Outlook activity from the pipeline canvas, then select theÂ **Settings**Â tab of the property area below the canvas to configure the email. Click onÂ **Sing in**Â button.
    
    ![swt17sye.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/swt17sye.jpg)
    
6. Select your Power BI organizational account and then selectÂ **Allow access**Â to confirm.
    
    ![eflvjiz9.jpg](https://labondemand.blob.core.windows.net/content/lab149562/instructions240859/eflvjiz9.jpg)